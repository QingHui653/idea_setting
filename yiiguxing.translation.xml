<application>
  <component name="AppStorage">
    <histories>
      <item value="restart From Head" />
      <item value="hop two nodes at a time" />
      <item value="Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become &quot;live&quot;." />
      <item value="Try to CAS head to p. If successful, repoint old head to itself * as sentinel for succ(), below." />
      <item value="Have to override just to update the javadoc" />
      <item value="Creates a {@code ConcurrentLinkedQueue} that is initially empty." />
      <item value="A node from which the last node on list (that is, the unique * node with node.next == null) can be reached in O(1) time. * Invariants: * - the last node is always reachable from tail via succ() * - tail != null * Non-invariants: * - tail.item may or may not be null. * - it is permitted for tail to lag behind head, that is, for tail * to not be reachable from head! * - tail.next may or may not be self-pointing to tail." />
      <item value="A node from which the first live (non-deleted) node (if any) * can be reached in O(1) time. * Invariants: * - all live nodes are reachable from head via succ() * - head != null * - (tmp = head).next != tmp || tmp != head * Non-invariants: * - head.item may or may not be null. * - it is permitted for tail to lag behind head, that is, for tail * to not be reachable from head!" />
      <item value="tail" />
      <item value="Unsafe mechanics" />
      <item value="Constructs a new node. Uses relaxed write because item can * only be seen after publication via casNext." />
      <item value="volatile" />
      <item value="CASing a Node's item reference to null atomically removes the * element from the queue. Iterators skip over Nodes with null * items. Prior implementations of this class had a race between * poll() and remove(Object) where the same element would appear * to be successfully removed by two concurrent operations. The * method remove(Object) also lazily unlinks deleted Nodes, but * this is merely an optimization." />
      <item value="Since head and tail are updated concurrently and independently, * it is possible for tail to lag behind head (why not)?" />
      <item value="Both head and tail are permitted to lag. In fact, failing to * update them every time one could is a significant optimization * (fewer CASes). As with LinkedTransferQueue (see the internal * documentation for that class), we use a slack threshold of two; * that is, we update head/tail when the current pointer appears * to be two or more steps away from the first/last node." />
      <item value="The above might appear to imply that all Nodes are GC-reachable * from a predecessor dequeued Node. That would cause two problems: * - allow a rogue Iterator to cause unbounded memory retention * - cause cross-generational linking of old Nodes to new Nodes if * a Node was tenured while live, which generational GCs have a * hard time dealing with, causing repeated major collections. * However, only non-deleted Nodes need to be reachable from * dequeued Nodes, and reachability does not necessarily have to * be of the kind understood by the GC. We use the trick of * linking a Node that has just been dequeued to itself. Such a * self-link implicitly means to advance to head." />
      <item value="The fundamental invariants are: * - There is exactly one (last) Node with a null next reference, * which is CASed when enqueueing. This last Node can be * reached in O(1) time from tail, but tail is merely an * optimization - it can always be reached in O(N) time from * head as well. * - The elements contained in the queue are the non-null items in * Nodes that are reachable from head. CASing the item * reference of a Node to null atomically removes it from the * queue. Reachability of all elements from head must remain * true even in the case of concurrent modifications that cause * head to advance. A dequeued Node may remain in use * indefinitely due to creation of an Iterator or simply a * poll() that has lost its time slice." />
      <item value="Note that like most non-blocking algorithms in this package, * this implementation relies on the fact that in garbage * collected systems, there is no possibility of ABA problems due * to recycled nodes, so there is no need to use &quot;counted * pointers&quot; or related techniques seen in versions used in * non-GC'ed settings." />
      <item value="Scott" />
      <item value="Michael" />
      <item value="This is a modification of the Michael &amp; Scott algorithm, * adapted for a garbage-collected environment, with support for * interior node deletion (to support remove(Object)). For * explanation, read the paper. *" />
      <item value="&lt;p&gt;This class is a member of the * &lt;a href=&quot;{@docRoot}/../technotes/guides/collections/index.html&quot;&gt; * Java Collections Framework&lt;/a&gt;." />
      <item value="&lt;p&gt;Memory consistency effects: As with other concurrent * collections, actions in a thread prior to placing an object into a * {@code ConcurrentLinkedQueue} * &lt;a href=&quot;package-summary.html#MemoryVisibility&quot;&gt;&lt;i&gt;happen-before&lt;/i&gt;&lt;/a&gt; * actions subsequent to the access or removal of that element from * the {@code ConcurrentLinkedQueue} in another thread." />
      <item value="&lt;p&gt;This class and its iterator implement all of the &lt;em&gt;optional&lt;/em&gt; * methods of the {@link Queue} and {@link Iterator} interfaces." />
      <item value="&lt;p&gt;Beware that, unlike in most collections, the {@code size} method * is &lt;em&gt;NOT&lt;/em&gt; a constant-time operation. Because of the * asynchronous nature of these queues, determining the current number * of elements requires a traversal of the elements, and so may report * inaccurate results if this collection is modified during traversal. * Additionally, the bulk operations {@code addAll}, * {@code removeAll}, {@code retainAll}, {@code containsAll}, * {@code equals}, and {@code toArray} are &lt;em&gt;not&lt;/em&gt; guaranteed * to be performed atomically. For example, an iterator operating * concurrently with an {@code addAll} operation might view only some * of the added elements." />
      <item value="&lt;p&gt;Iterators are &lt;i&gt;weakly consistent&lt;/i&gt;, returning elements * reflecting the state of the queue at some point at or since the * creation of the iterator. They do &lt;em&gt;not&lt;/em&gt; throw {@link * java.util.ConcurrentModificationException}, and may proceed concurrently * with other operations. Elements contained in the queue since the creation * of the iterator will be returned exactly once." />
      <item value="&lt;p&gt;This implementation employs an efficient &amp;quot;wait-free&amp;quot; * algorithm based on one described in &lt;a * href=&quot;http://www.cs.rochester.edu/u/michael/PODC96.html&quot;&gt; Simple, * Fast, and Practical Non-Blocking and Blocking Concurrent Queue * Algorithms&lt;/a&gt; by Maged M. Michael and Michael L. Scott." />
      <item value="An unbounded thread-safe {@linkplain Queue queue} based on linked nodes. * This queue orders elements FIFO (first-in-first-out). * The &lt;em&gt;head&lt;/em&gt; of the queue is that element that has been on the * queue the longest time. * The &lt;em&gt;tail&lt;/em&gt; of the queue is that element that has been on the * queue the shortest time. New elements * are inserted at the tail of the queue, and the queue retrieval * operations obtain elements at the head of the queue. * A {@code ConcurrentLinkedQueue} is an appropriate choice when * many threads will share access to a common collection. * Like most other concurrent collection implementations, this class * does not permit the use of {@code null} elements." />
      <item value="An unbounded thread-safe queue based on linked nodes. This queue orders elements FIFO (first-in-first-out). The head of the queue is that element that has been on the queue the longest time. The tail of the queue is that element that has been on the queue the shortest time. New elements are inserted at the tail of the queue, and the queue retrieval operations obtain elements at the head of the queue. A ConcurrentLinkedQueue is an appropriate choice when many threads will share access to a common collection. Like most other concurrent collection implementations, this class does not permit the use of null elements. This implementation employs an efficient &quot;wait-free&quot; algorithm based on one described in Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms by Maged M. Michael and Michael L. Scott." />
      <item value="We extend the techniques developed for ConcurrentLinkedQueue and * LinkedTransferQueue (see the internal docs for those classes). * Understanding the ConcurrentLinkedQueue implementation is a * prerequisite for understanding the implementation of this class." />
      <item value="This is an implementation of a concurrent lock-free deque * supporting interior removes but not interior insertions, as * required to support the entire Deque interface." />
      <item value="Iterators are weakly consistent, returning elements reflecting the state of the deque at some point at or since the creation of the iterator. They do not throw ConcurrentModificationException, and may proceed concurrently with other operations. Beware that, unlike in most collections, the size method is NOT a constant-time operation. Because of the asynchronous nature of these deques, determining the current number of elements requires a traversal of the elements, and so may report inaccurate results if this collection is modified during traversal. Additionally, the bulk operations addAll, removeAll, retainAll, containsAll, equals, and toArray are not guaranteed to be performed atomically. For example, an iterator operating concurrently with an addAll operation might view only some of the added elements. This class and its iterator implement all of the optional methods of the Deque and Iterator interfaces. Memory consistency effects: As with other concurrent collections, actions in a thread prior to placing an object into a ConcurrentLinkedDeque happen-before actions subsequent to the access or removal of that element from the ConcurrentLinkedDeque in another thread. This class is a member of the Java Collections Framework." />
      <item value="An unbounded concurrent deque based on linked nodes. Concurrent insertion, removal, and access operations execute safely across multiple threads. A ConcurrentLinkedDeque is an appropriate choice when many threads will share access to a common collection. Like most other concurrent collection implementations, this class does not permit the use of null elements." />
      <item value="Completion" />
      <item value="Completion Service" />
      <item value="A service that decouples the production of new asynchronous tasks from the consumption of the results of completed tasks. Producers submit tasks for execution. Consumers take completed tasks and process their results in the order they complete. A CompletionService can for example be used to manage asynchronous IO, in which tasks that perform reads are submitted in one part of a program or system, and then acted upon in a different part of the program when the reads complete, possibly in a different order than they were requested. Typically, a CompletionService relies on a separate Executor to actually execute the tasks, in which case the CompletionService only manages an internal completion queue. The ExecutorCompletionService class provides an implementation of this approach. Memory consistency effects: Actions in a thread prior to submitting a task to a CompletionService happen-before actions taken by that task, which in turn happen-before actions following a successful return from the corresponding take()." />
      <item value="Exception indicating that the result of a value-producing task, * such as a {@link FutureTask}, cannot be retrieved because the task * was cancelled." />
      <item value="if unable to compute a resul" />
      <item value="computed result" />
      <item value="Computes a result, or throws an exception if unable to do so." />
      <item value="Cyclic Barrier" />
      <item value="Exception thrown when a thread tries to wait upon a barrier that is in a broken state, or which enters the broken state while the thread is waiting." />
      <item value="Inserts the specified element into this queue if it is possible to do * so immediately without violating capacity restrictions, returning * &lt;tt&gt;true&lt;/tt&gt; upon success and &lt;tt&gt;false&lt;/tt&gt; if no space is currently * available. When using a capacity-restricted queue, this method is * generally preferable to {@link #add}, which can fail to insert an * element only by throwing an exception." />
      <item value="Blocking Deque" />
      <item value="Inserts the specified element at the tail of this queue, waiting * up to the specified wait time for space to become available if * the queue is full." />
      <item value="lock Interruptibly" />
      <item value="Lock only for visibility, not mutual exclusion" />
      <item value="// Lock only for visibility, not mutual exclusion" />
      <item value="Creates an {@code ArrayBlockingQueue} with the given (fixed) * capacity, the specified access policy and initially containing the * elements of the given collection, * added in traversal order of the collection's iterator." />
      <item value="if {@code true} then queue accesses for threads blocked * on insertion or removal, are processed in FIFO order; * if {@code false} the access order is unspecified." />
    </histories>
  </component>
  <component name="Settings">
    <option name="ignoreRegExp" value="" />
  </component>
</application>